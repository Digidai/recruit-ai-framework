#!/usr/bin/env python3
"""
å…¨é¢é¡¹ç›®é—®é¢˜æ£€æŸ¥ï¼š
1. ç¿»è¯‘é—®é¢˜ï¼ˆname = name_enï¼‰
2. æ ‡ç­¾è§„èŒƒæ€§
3. URL æ ¼å¼é—®é¢˜
4. é‡å¤èµ„æº
5. ç©ºåˆ†ç±»
6. ç»“æ„é—®é¢˜
7. ç¼ºå¤±å­—æ®µ
8. æ ‡ç­¾ä½¿ç”¨åˆ†æ
"""

import json
import os
import re
from collections import defaultdict
from urllib.parse import urlparse


def check_all(node, issues, stats, path="", seen_urls=None, seen_names=None):
    """é€’å½’æ£€æŸ¥æ‰€æœ‰é—®é¢˜"""
    if seen_urls is None:
        seen_urls = {}
    if seen_names is None:
        seen_names = {}

    name = node.get('name', '')
    name_en = node.get('name_en', '')
    url = node.get('url', '')
    tags = node.get('tags', [])
    children = node.get('children', [])

    current_path = f"{path} > {name}" if path else name
    stats['total'] += 1

    # 1. æ£€æŸ¥ç¿»è¯‘é—®é¢˜
    if name and name_en:
        name_norm = name.replace('ï½œ', '|').replace('ï¼š', ':').strip()
        name_en_norm = name_en.replace('ï½œ', '|').replace('ï¼š', ':').strip()
        if name_norm == name_en_norm:
            issues['translation_same'].append({
                'name': name,
                'path': current_path
            })

    # 2. æ£€æŸ¥ name_en ä¸­åŒ…å«ä¸­æ–‡
    if name_en and re.search(r'[\u4e00-\u9fff]', name_en):
        issues['chinese_in_name_en'].append({
            'name': name,
            'name_en': name_en,
            'path': current_path
        })

    # 3. æ£€æŸ¥ç¼ºå¤± name_en
    if name and not name_en and (url or children):
        issues['missing_name_en'].append({
            'name': name,
            'path': current_path
        })

    # URL èŠ‚ç‚¹æ£€æŸ¥
    if url:
        stats['url'] += 1

        # 4. æ£€æŸ¥ URL æ ¼å¼
        if not url.startswith('http://') and not url.startswith('https://'):
            issues['invalid_url_format'].append({
                'name': name,
                'url': url,
                'path': current_path
            })

        # 5. æ£€æŸ¥é‡å¤ URL
        if url in seen_urls:
            issues['duplicate_url'].append({
                'name': name,
                'url': url,
                'original': seen_urls[url],
                'path': current_path
            })
        else:
            seen_urls[url] = current_path

        # 6. æ£€æŸ¥ URL ç¼–ç é—®é¢˜
        if '%' in url and re.search(r'%[^0-9A-Fa-f]|%[0-9A-Fa-f][^0-9A-Fa-f]', url):
            issues['url_encoding'].append({
                'name': name,
                'url': url,
                'path': current_path
            })

        # 7. æ£€æŸ¥ç¼ºå¤±æ ‡ç­¾
        if not tags:
            issues['missing_tags'].append({
                'name': name,
                'path': current_path
            })

        # 8. ç»Ÿè®¡æ ‡ç­¾
        for tag in tags:
            stats['tags'][tag] += 1

        # 9. æ£€æŸ¥æ ‡ç­¾å¤§å°å†™ä¸ä¸€è‡´
        for tag in tags:
            lower = tag.lower()
            if lower != tag and tag != tag.upper() and tag != tag.title():
                issues['tag_case_inconsistent'].append({
                    'name': name,
                    'tag': tag,
                    'path': current_path
                })

    # æ–‡ä»¶å¤¹èŠ‚ç‚¹æ£€æŸ¥
    else:
        stats['folder'] += 1

        # 10. æ£€æŸ¥ç©ºæ–‡ä»¶å¤¹
        if not children:
            issues['empty_folder'].append({
                'name': name,
                'path': current_path
            })

        # 11. æ£€æŸ¥åªæœ‰1ä¸ªå­èŠ‚ç‚¹çš„æ–‡ä»¶å¤¹
        elif len(children) == 1:
            child = children[0]
            if 'url' not in child and child.get('type') != 'template':
                issues['single_child_folder'].append({
                    'name': name,
                    'child': child.get('name', ''),
                    'path': current_path
                })

        # 12. æ£€æŸ¥èµ„æºè¿‡å°‘çš„å¶å­åˆ†ç±»ï¼ˆ<3ä¸ªï¼‰
        url_children = [c for c in children if c.get('url') or c.get('type') == 'template']
        folder_children = [c for c in children if not c.get('url') and c.get('type') != 'template']
        if len(folder_children) == 0 and 0 < len(url_children) < 3:
            issues['few_resources'].append({
                'name': name,
                'count': len(url_children),
                'path': current_path
            })

    # 13. æ£€æŸ¥é‡å¤åç§°
    if name:
        if name in seen_names and url:  # åªæ£€æŸ¥ URL èŠ‚ç‚¹
            issues['duplicate_name'].append({
                'name': name,
                'original': seen_names[name],
                'path': current_path
            })
        elif url:
            seen_names[name] = current_path

    # é€’å½’æ£€æŸ¥å­èŠ‚ç‚¹
    for child in children:
        check_all(child, issues, stats, current_path, seen_urls, seen_names)


def analyze_tags(stats):
    """åˆ†ææ ‡ç­¾ä½¿ç”¨æƒ…å†µ"""
    tag_issues = []

    # æ£€æŸ¥ä½é¢‘æ ‡ç­¾
    for tag, count in stats['tags'].items():
        if count == 1:
            tag_issues.append(f"ä»…ä½¿ç”¨1æ¬¡: {tag}")

    # æ£€æŸ¥å¯èƒ½çš„å¤§å°å†™é‡å¤
    lower_tags = defaultdict(list)
    for tag in stats['tags']:
        lower_tags[tag.lower()].append(tag)

    for lower, variants in lower_tags.items():
        if len(variants) > 1:
            tag_issues.append(f"å¤§å°å†™é‡å¤: {variants}")

    return tag_issues


def main():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    tarf_path = os.path.join(script_dir, 'docs', 'tarf.json')
    with open(tarf_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    issues = {
        'translation_same': [],
        'chinese_in_name_en': [],
        'missing_name_en': [],
        'invalid_url_format': [],
        'duplicate_url': [],
        'url_encoding': [],
        'missing_tags': [],
        'tag_case_inconsistent': [],
        'empty_folder': [],
        'single_child_folder': [],
        'few_resources': [],
        'duplicate_name': [],
    }

    stats = {
        'total': 0,
        'url': 0,
        'folder': 0,
        'tags': defaultdict(int),
    }

    check_all(data, issues, stats)
    tag_issues = analyze_tags(stats)

    # è¾“å‡ºæŠ¥å‘Š
    print("=" * 70)
    print("é¡¹ç›®é—®é¢˜æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 70)

    print(f"\nã€åŸºç¡€ç»Ÿè®¡ã€‘")
    print(f"  æ€»èŠ‚ç‚¹æ•°:    {stats['total']}")
    print(f"  URL èµ„æº:    {stats['url']}")
    print(f"  åˆ†ç±»æ–‡ä»¶å¤¹:  {stats['folder']}")
    print(f"  æ ‡ç­¾ç§ç±»:    {len(stats['tags'])}")

    # é—®é¢˜æ±‡æ€»
    print(f"\nã€é—®é¢˜æ±‡æ€»ã€‘")
    total_issues = 0
    issue_summary = [
        ('ç¿»è¯‘ç›¸åŒ (name=name_en)', 'translation_same', 'é«˜'),
        ('name_en å«ä¸­æ–‡', 'chinese_in_name_en', 'é«˜'),
        ('ç¼ºå¤± name_en', 'missing_name_en', 'ä¸­'),
        ('URL æ ¼å¼é”™è¯¯', 'invalid_url_format', 'é«˜'),
        ('é‡å¤ URL', 'duplicate_url', 'é«˜'),
        ('URL ç¼–ç é—®é¢˜', 'url_encoding', 'ä½'),
        ('ç¼ºå¤±æ ‡ç­¾', 'missing_tags', 'ä¸­'),
        ('æ ‡ç­¾å¤§å°å†™ä¸ä¸€è‡´', 'tag_case_inconsistent', 'ä½'),
        ('ç©ºåˆ†ç±»', 'empty_folder', 'é«˜'),
        ('å•å­èŠ‚ç‚¹åˆ†ç±»', 'single_child_folder', 'ä½'),
        ('èµ„æºè¿‡å°‘(<3)', 'few_resources', 'ä¸­'),
        ('é‡å¤åç§°', 'duplicate_name', 'ä½'),
    ]

    for desc, key, severity in issue_summary:
        count = len(issues[key])
        total_issues += count
        if count > 0:
            icon = "ğŸ”´" if severity == 'é«˜' else "ğŸŸ¡" if severity == 'ä¸­' else "ğŸŸ¢"
            print(f"  {icon} {desc}: {count} ä¸ª")
        else:
            print(f"  âœ… {desc}: 0 ä¸ª")

    # è¯¦ç»†é—®é¢˜åˆ—è¡¨
    print(f"\n{'=' * 70}")
    print("è¯¦ç»†é—®é¢˜åˆ—è¡¨")
    print("=" * 70)

    # é«˜ä¼˜å…ˆçº§é—®é¢˜
    if issues['translation_same']:
        print(f"\nã€ç¿»è¯‘ç›¸åŒã€‘å…± {len(issues['translation_same'])} ä¸ª")
        for item in issues['translation_same'][:10]:
            print(f"  - {item['name']}")
        if len(issues['translation_same']) > 10:
            print(f"  ... è¿˜æœ‰ {len(issues['translation_same']) - 10} ä¸ª")

    if issues['chinese_in_name_en']:
        print(f"\nã€name_en å«ä¸­æ–‡ã€‘å…± {len(issues['chinese_in_name_en'])} ä¸ª")
        for item in issues['chinese_in_name_en'][:10]:
            print(f"  - {item['name']}")
            print(f"    name_en: {item['name_en']}")
        if len(issues['chinese_in_name_en']) > 10:
            print(f"  ... è¿˜æœ‰ {len(issues['chinese_in_name_en']) - 10} ä¸ª")

    if issues['duplicate_url']:
        print(f"\nã€é‡å¤ URLã€‘å…± {len(issues['duplicate_url'])} ä¸ª")
        for item in issues['duplicate_url'][:10]:
            print(f"  - {item['name']}")
            print(f"    URL: {item['url']}")
            print(f"    åŸå§‹: {item['original'].split(' > ')[-1]}")
        if len(issues['duplicate_url']) > 10:
            print(f"  ... è¿˜æœ‰ {len(issues['duplicate_url']) - 10} ä¸ª")

    if issues['missing_tags']:
        print(f"\nã€ç¼ºå¤±æ ‡ç­¾ã€‘å…± {len(issues['missing_tags'])} ä¸ª")
        for item in issues['missing_tags'][:10]:
            print(f"  - {item['name']}")
        if len(issues['missing_tags']) > 10:
            print(f"  ... è¿˜æœ‰ {len(issues['missing_tags']) - 10} ä¸ª")

    if issues['few_resources']:
        print(f"\nã€èµ„æºè¿‡å°‘ã€‘å…± {len(issues['few_resources'])} ä¸ª")
        for item in issues['few_resources']:
            print(f"  - [{item['count']}] {item['name']}")

    if issues['empty_folder']:
        print(f"\nã€ç©ºåˆ†ç±»ã€‘å…± {len(issues['empty_folder'])} ä¸ª")
        for item in issues['empty_folder']:
            print(f"  - {item['name']}")

    # æ ‡ç­¾åˆ†æ
    if tag_issues:
        print(f"\nã€æ ‡ç­¾é—®é¢˜ã€‘å…± {len(tag_issues)} ä¸ª")
        for issue in tag_issues[:20]:
            print(f"  - {issue}")
        if len(tag_issues) > 20:
            print(f"  ... è¿˜æœ‰ {len(tag_issues) - 20} ä¸ª")

    # æ€»ç»“
    print(f"\n{'=' * 70}")
    print("é—®é¢˜æ€»ç»“")
    print("=" * 70)

    high_priority = (
        len(issues['translation_same']) +
        len(issues['chinese_in_name_en']) +
        len(issues['invalid_url_format']) +
        len(issues['duplicate_url']) +
        len(issues['empty_folder'])
    )

    medium_priority = (
        len(issues['missing_name_en']) +
        len(issues['missing_tags']) +
        len(issues['few_resources'])
    )

    low_priority = (
        len(issues['url_encoding']) +
        len(issues['tag_case_inconsistent']) +
        len(issues['single_child_folder']) +
        len(issues['duplicate_name'])
    )

    print(f"  ğŸ”´ é«˜ä¼˜å…ˆçº§: {high_priority} ä¸ª")
    print(f"  ğŸŸ¡ ä¸­ä¼˜å…ˆçº§: {medium_priority} ä¸ª")
    print(f"  ğŸŸ¢ ä½ä¼˜å…ˆçº§: {low_priority} ä¸ª")
    print(f"  ğŸ“Š æ€»è®¡: {total_issues} ä¸ªé—®é¢˜")

    if total_issues == 0:
        print(f"\n  âœ… æ­å–œï¼æœªå‘ç°ä»»ä½•é—®é¢˜ã€‚")
    elif high_priority == 0:
        print(f"\n  âœ… æ— é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼Œé¡¹ç›®çŠ¶æ€è‰¯å¥½ã€‚")
    else:
        print(f"\n  âš ï¸ å»ºè®®ä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§é—®é¢˜ã€‚")


if __name__ == '__main__':
    main()
